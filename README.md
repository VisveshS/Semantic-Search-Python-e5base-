In high-dim (**768**) semantic space, graph topology gives better insight than euclidian geometry
(curse of dimensionality makes absolute distances hard to interpret), so analyzing KNN Relationships between embeddings is more meaningful

Embedding used : [huggingface e5-base-v2](https://huggingface.co/intfloat/e5-base-v2)

<img width="512" height="512" alt="sentenceembedding" src="https://github.com/user-attachments/assets/53911596-187f-494d-b249-01c87b024f3a" />
